# Robots.txt for Precast.dev
# https://precast.dev

# Allow all crawlers
User-agent: *
Allow: /

# Sitemap location
Sitemap: https://precast.dev/sitemap.xml

# Crawl delay (in seconds) - optional, helps prevent server overload
Crawl-delay: 1

# Disallow access to internal API endpoints if any
Disallow: /api/internal/
Disallow: /.well-known/

# Allow social media crawlers full access
User-agent: facebookexternalhit
Allow: /

User-agent: Twitterbot
Allow: /

User-agent: LinkedInBot
Allow: /

User-agent: WhatsApp
Allow: /

User-agent: Slackbot
Allow: /

# Block bad bots
User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: MJ12bot
Disallow: /

# Allow search engine bots
User-agent: Googlebot
Allow: /
Crawl-delay: 0

User-agent: Bingbot
Allow: /
Crawl-delay: 0

User-agent: DuckDuckBot
Allow: /
Crawl-delay: 0

User-agent: Baiduspider
Allow: /
Crawl-delay: 1

User-agent: YandexBot
Allow: /
Crawl-delay: 1